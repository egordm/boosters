{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bf0c0c2",
   "metadata": {},
   "source": [
    "# Tutorial 08: Explainability\n",
    "\n",
    "ðŸŸ¡ **Intermediate** â€” Familiarity with ML concepts helpful\n",
    "\n",
    "Learn how to interpret boosted model predictions using feature importance and SHAP values.\n",
    "\n",
    "## What you'll learn\n",
    "\n",
    "1. Built-in feature importance (split-based)\n",
    "2. SHAP values for local explanations\n",
    "3. Visualizing feature contributions\n",
    "4. Interpreting GBLinear coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb59634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import boosters\n",
    "from boosters.sklearn import GBDTRegressor, GBLinearRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b13ef25",
   "metadata": {},
   "source": [
    "## Load California Housing Dataset\n",
    "\n",
    "We'll use the California housing dataset which has meaningful, interpretable feature names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e249656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load California housing - predicting median house value\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "feature_names = data.feature_names\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"California Housing Dataset\")\n",
    "print(f\"Samples: {len(X)}, Features: {len(feature_names)}\")\n",
    "print(f\"\\nFeature names:\")\n",
    "for i, name in enumerate(feature_names):\n",
    "    print(f\"  {i}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6134f5c",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c86f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GBDT regressor\n",
    "model = GBDTRegressor(n_estimators=100, max_depth=6, learning_rate=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"RÂ² Score: {model.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a3da85",
   "metadata": {},
   "source": [
    "## Built-in Feature Importance\n",
    "\n",
    "GBDT models track feature importance based on split gain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec1e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "importance = model.feature_importances_\n",
    "\n",
    "# Sort by importance\n",
    "indices = np.argsort(importance)[::-1]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(range(len(importance)), importance[indices][::-1])\n",
    "plt.yticks(range(len(importance)), [feature_names[i] for i in indices][::-1])\n",
    "plt.xlabel('Importance (Gain)')\n",
    "plt.title('Feature Importance - California Housing')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop features for predicting house value:\")\n",
    "for i in indices[:5]:\n",
    "    print(f\"  {feature_names[i]}: {importance[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528fb12c",
   "metadata": {},
   "source": [
    "## SHAP Values\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) values show how each feature contributes to individual predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9f2a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SHAP values for first 100 test samples\n",
    "# Access the underlying model via model_ and wrap data in Dataset\n",
    "shap_values = model.model_.shap_values(boosters.Dataset(X_test[:100]))\n",
    "\n",
    "print(f\"SHAP values shape: {shap_values.shape}\")\n",
    "print(f\"  (samples, features + 1 bias, outputs)\")\n",
    "\n",
    "# Mean absolute SHAP value per feature (global importance)\n",
    "# Shape is (samples, features+1, outputs) - take first output, exclude bias\n",
    "mean_shap = np.abs(shap_values[:, :-1, 0]).mean(axis=0)\n",
    "shap_indices = np.argsort(mean_shap)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(range(len(mean_shap)), mean_shap[shap_indices][::-1])\n",
    "plt.yticks(range(len(mean_shap)), [feature_names[i] for i in shap_indices][::-1])\n",
    "plt.xlabel('Mean |SHAP value|')\n",
    "plt.title('SHAP Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fe8e73",
   "metadata": {},
   "source": [
    "## Explain a Single Prediction\n",
    "\n",
    "Let's explain why the model predicted a specific house value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c4d631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a sample to explain\n",
    "sample_idx = 0\n",
    "sample = X_test[sample_idx]\n",
    "prediction = model.predict(sample.reshape(1, -1))[0]\n",
    "actual = y_test[sample_idx]\n",
    "\n",
    "print(f\"Prediction: ${prediction * 100000:.0f}\")\n",
    "print(f\"Actual:     ${actual * 100000:.0f}\")\n",
    "print(f\"\\nFeature contributions (SHAP values):\")\n",
    "\n",
    "# Get SHAP values for this sample (first output, exclude bias)\n",
    "sample_shap = shap_values[sample_idx, :-1, 0]\n",
    "bias = shap_values[sample_idx, -1, 0]\n",
    "\n",
    "# Waterfall-style breakdown\n",
    "contributions = list(zip(feature_names, sample_shap, sample))\n",
    "contributions.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "print(f\"\\nBase value (bias): {bias:.3f}\")\n",
    "for name, shap_val, feat_val in contributions:\n",
    "    direction = \"â†‘\" if shap_val > 0 else \"â†“\"\n",
    "    print(f\"  {name}={feat_val:.2f}: {shap_val:+.3f} {direction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db6aaee",
   "metadata": {},
   "source": [
    "## GBLinear: Direct Coefficient Interpretation\n",
    "\n",
    "Linear models have directly interpretable coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e10b750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GBLinear for comparison\n",
    "linear_model = GBLinearRegressor(n_estimators=100, learning_rate=0.3)\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"GBLinear RÂ² Score: {linear_model.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31969baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coefficients - directly interpretable!\n",
    "coef = linear_model.coef_\n",
    "\n",
    "# Sort by absolute value\n",
    "coef_indices = np.argsort(np.abs(coef))[::-1]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "colors = ['green' if c > 0 else 'red' for c in coef[coef_indices][::-1]]\n",
    "plt.barh(range(len(coef)), coef[coef_indices][::-1], color=colors)\n",
    "plt.yticks(range(len(coef)), [feature_names[i] for i in coef_indices][::-1])\n",
    "plt.xlabel('Coefficient')\n",
    "plt.title('GBLinear Coefficients - California Housing')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Interpretation:\")\n",
    "print(\"  Green = higher value â†’ higher house price\")\n",
    "print(\"  Red = higher value â†’ lower house price\")\n",
    "print(f\"\\nIntercept: {float(linear_model.intercept_[0]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21f3c24",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "1. âœ… Built-in feature importance from split gain\n",
    "2. âœ… SHAP values for local explanations of individual predictions\n",
    "3. âœ… How to interpret which features drive predictions\n",
    "4. âœ… Direct coefficient interpretation with GBLinear\n",
    "\n",
    "**Key insights from California Housing:**\n",
    "- `MedInc` (median income) is the strongest predictor of house value\n",
    "- Location features (`Latitude`, `Longitude`) capture geographic price variation\n",
    "- `AveOccup` (average occupancy) and `HouseAge` also contribute\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- [Tutorial 09: Model Serialization](09-model-serialization.ipynb) â€” Save and load models\n",
    "- [User Guide: Explainability](../user-guide/explainability.rst) â€” Full documentation"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
