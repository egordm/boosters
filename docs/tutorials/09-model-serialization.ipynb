{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ea275eb",
   "metadata": {},
   "source": [
    "# Tutorial 09: Model Serialization\n",
    "\n",
    "ðŸŸ¡ **Intermediate** â€” Familiarity with ML concepts helpful\n",
    "\n",
    "Learn how to save, load, and manage boosters models for deployment.\n",
    "\n",
    "## What you'll learn\n",
    "\n",
    "1. Save models with boosters' native binary format\n",
    "2. Save models as JSON for inspection\n",
    "3. Load models for inference\n",
    "4. Model versioning best practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b08dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import boosters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6785af",
   "metadata": {},
   "source": [
    "## Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a894e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and train\n",
    "X, y = make_regression(n_samples=1000, n_features=10, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create datasets\n",
    "train_data = boosters.Dataset(X_train, y_train)\n",
    "test_data = boosters.Dataset(X_test)\n",
    "\n",
    "# Train model - use max_depth=3 for cleaner tree visualization later\n",
    "config = boosters.GBDTConfig(n_estimators=100, max_depth=3, learning_rate=0.1)\n",
    "model = boosters.GBDTModel.train(train_data, config=config)\n",
    "\n",
    "# Baseline predictions\n",
    "y_pred_original = model.predict(test_data)\n",
    "\n",
    "print(f\"Model trained with {model.n_trees} trees\")\n",
    "print(f\"Predictions shape: {y_pred_original.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50059255",
   "metadata": {},
   "source": [
    "## Save with Native Binary Format\n",
    "\n",
    "boosters uses a compact binary format (`.bstr`) for efficient model storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55f5455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temp directory for examples\n",
    "tmpdir = tempfile.mkdtemp()\n",
    "\n",
    "# Serialize to binary bytes\n",
    "model_bytes = model.to_bytes()\n",
    "\n",
    "# Save to file\n",
    "binary_path = Path(tmpdir) / \"model.bstr\"\n",
    "binary_path.write_bytes(model_bytes)\n",
    "\n",
    "file_size = binary_path.stat().st_size\n",
    "print(f\"Model saved to: {binary_path}\")\n",
    "print(f\"File size: {file_size / 1024:.1f} KB\")\n",
    "print(f\"Bytes in memory: {len(model_bytes) / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638ba318",
   "metadata": {},
   "source": [
    "## Load from Binary Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314b57a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from file\n",
    "loaded_bytes = binary_path.read_bytes()\n",
    "loaded_model = boosters.GBDTModel.from_bytes(loaded_bytes)\n",
    "\n",
    "# Verify predictions match\n",
    "y_pred_loaded = loaded_model.predict(test_data)\n",
    "\n",
    "print(f\"Loaded model trees: {loaded_model.n_trees}\")\n",
    "print(f\"Predictions match: {np.allclose(y_pred_original, y_pred_loaded)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6338bdc7",
   "metadata": {},
   "source": [
    "## Save as JSON (Human-Readable)\n",
    "\n",
    "For debugging or interoperability, save as JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28146c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize to JSON bytes\n",
    "json_bytes = model.to_json_bytes()\n",
    "\n",
    "# Save to file\n",
    "json_path = Path(tmpdir) / \"model.bstr.json\"\n",
    "json_path.write_bytes(json_bytes)\n",
    "\n",
    "json_size = json_path.stat().st_size\n",
    "print(f\"JSON file size: {json_size / 1024:.1f} KB\")\n",
    "print(f\"Binary is {json_size / file_size:.1f}x smaller than JSON\")\n",
    "\n",
    "# Peek at the JSON structure\n",
    "json_preview = json.loads(json_bytes)\n",
    "print(f\"\\nJSON keys: {list(json_preview.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a356181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from JSON\n",
    "loaded_json = boosters.GBDTModel.from_json_bytes(json_path.read_bytes())\n",
    "\n",
    "y_pred_json = loaded_json.predict(test_data)\n",
    "print(f\"JSON model predictions match: {np.allclose(y_pred_original, y_pred_json)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c84c4e",
   "metadata": {},
   "source": [
    "## Visualize Tree Structure\n",
    "\n",
    "Use `plot_tree` to visualize individual trees from a model.\n",
    "This is useful for debugging and understanding model decisions.\n",
    "We used `max_depth=3` above to keep the visualization readable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed09ebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define feature names for readable visualization\n",
    "feature_names = [f'feature_{i}' for i in range(10)]\n",
    "\n",
    "# Visualize first tree\n",
    "ax = boosters.plot_tree(model, tree_index=0, feature_names=feature_names)\n",
    "plt.title(\"Tree 0: First boosting round\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42d742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tree structure as a DataFrame for programmatic analysis\n",
    "df = boosters.tree_to_dataframe(model, tree_index=0, feature_names=feature_names)\n",
    "\n",
    "print(\"Tree structure (first 10 nodes):\")\n",
    "print(df.head(10).to_string())\n",
    "\n",
    "# Find the most important splits\n",
    "splits = df[~df['is_leaf']].sort_values('gain', ascending=False)\n",
    "print(f\"\\nTop 3 splits by gain:\")\n",
    "for _, row in splits.head(3).iterrows():\n",
    "    print(f\"  {row['feature']} â‰¤ {row['threshold']:.3f} (gain={row['gain']:.1f}, cover={row['cover']:.0f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7e2699",
   "metadata": {},
   "source": [
    "## Model Metadata\n",
    "\n",
    "Store metadata alongside your model for versioning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de2e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def compute_model_signature(model, X_sample):\n",
    "    \"\"\"Compute a signature for model verification.\"\"\"\n",
    "    predictions = model.predict(boosters.Dataset(X_sample[:10]))\n",
    "    return hashlib.md5(predictions.tobytes()).hexdigest()\n",
    "\n",
    "# Calculate RÂ² score\n",
    "y_pred_flat = y_pred_original.flatten()\n",
    "original_score = r2_score(y_test, y_pred_flat)\n",
    "\n",
    "# Create metadata\n",
    "metadata = {\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"created\": datetime.now().isoformat(),\n",
    "    \"model_type\": \"GBDTModel\",\n",
    "    \"n_features\": X_train.shape[1],\n",
    "    \"n_trees\": model.n_trees,\n",
    "    \"n_samples_trained\": X_train.shape[0],\n",
    "    \"metrics\": {\n",
    "        \"test_r2\": float(original_score),\n",
    "    },\n",
    "    \"signature\": compute_model_signature(model, X_test),\n",
    "}\n",
    "\n",
    "# Save metadata alongside model\n",
    "metadata_path = Path(tmpdir) / \"model_metadata.json\"\n",
    "metadata_path.write_text(json.dumps(metadata, indent=2))\n",
    "\n",
    "print(\"Model Metadata:\")\n",
    "print(json.dumps(metadata, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91d0ab5",
   "metadata": {},
   "source": [
    "## Verify Loaded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575f77ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_model(model, metadata, X_sample):\n",
    "    \"\"\"Verify a loaded model matches its metadata.\"\"\"\n",
    "    # Check signature\n",
    "    current_signature = compute_model_signature(model, X_sample)\n",
    "    if current_signature != metadata[\"signature\"]:\n",
    "        raise ValueError(\"Model signature mismatch!\")\n",
    "    \n",
    "    # Check features\n",
    "    if X_sample.shape[1] != metadata[\"n_features\"]:\n",
    "        raise ValueError(f\"Expected {metadata['n_features']} features, got {X_sample.shape[1]}\")\n",
    "    \n",
    "    print(\"âœ… Model verified successfully!\")\n",
    "    print(f\"   Version: {metadata['version']}\")\n",
    "    print(f\"   Created: {metadata['created']}\")\n",
    "    print(f\"   Trees: {metadata['n_trees']}\")\n",
    "    print(f\"   Test RÂ²: {metadata['metrics']['test_r2']:.4f}\")\n",
    "\n",
    "# Load and verify\n",
    "loaded_metadata = json.loads(metadata_path.read_text())\n",
    "verify_model(loaded_model, loaded_metadata, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e320c637",
   "metadata": {},
   "source": [
    "## GBLinear Models\n",
    "\n",
    "The same API works for GBLinear models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8130637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a GBLinear model\n",
    "linear_config = boosters.GBLinearConfig(n_estimators=50, learning_rate=0.5)\n",
    "linear_model = boosters.GBLinearModel.train(train_data, config=linear_config)\n",
    "\n",
    "# Save and load\n",
    "linear_bytes = linear_model.to_bytes()\n",
    "linear_path = Path(tmpdir) / \"linear_model.bstr\"\n",
    "linear_path.write_bytes(linear_bytes)\n",
    "\n",
    "loaded_linear = boosters.GBLinearModel.from_bytes(linear_path.read_bytes())\n",
    "\n",
    "# Verify\n",
    "y_pred_linear_orig = linear_model.predict(test_data)\n",
    "y_pred_linear_load = loaded_linear.predict(test_data)\n",
    "\n",
    "print(f\"GBLinear model size: {len(linear_bytes) / 1024:.1f} KB\")\n",
    "print(f\"Predictions match: {np.allclose(y_pred_linear_orig, y_pred_linear_load)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27cb260",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe36e48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List saved files\n",
    "print(\"Saved files:\")\n",
    "for f in sorted(Path(tmpdir).iterdir()):\n",
    "    print(f\"  {f.name}: {f.stat().st_size / 1024:.1f} KB\")\n",
    "\n",
    "# Cleanup\n",
    "import shutil\n",
    "shutil.rmtree(tmpdir)\n",
    "print(f\"\\nCleaned up: {tmpdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a5175c",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "1. **Use binary format for production** â€” Smaller files, faster loading\n",
    "2. **Use JSON for debugging** â€” Human-readable, inspectable\n",
    "3. **Always save metadata** â€” Version, creation date, metrics, signature\n",
    "4. **Verify after loading** â€” Check signatures to catch corruption\n",
    "5. **Version your models** â€” Use semantic versioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecf4233",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "1. âœ… Save models with `.to_bytes()` (compact binary format)\n",
    "2. âœ… Save models with `.to_json_bytes()` (human-readable)\n",
    "3. âœ… Load models with `.from_bytes()` and `.from_json_bytes()`\n",
    "4. âœ… Create and verify model metadata\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- [API Reference](../api/index.rst) â€” Complete API documentation\n",
    "- [Tutorial 10: Linear Trees](10-linear-trees.ipynb) â€” Advanced tree configurations"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
