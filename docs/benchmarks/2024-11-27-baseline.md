# Benchmark Results

Baseline performance measurements for booste-rs prediction.

## Test Environment

- **Date**: 2024-11-27
- **CPU**: (run `lscpu` for details)
- **booste-rs version**: 0.1.0 (commit TBD)
- **XGBoost version**: 3.0.0 (via `xgb` crate)

## Benchmark Models

| Model | Trees | Features | Max Depth | File Size |
|-------|-------|----------|-----------|-----------|
| `bench_small` | 10 | 5 | 3 | 12 KB |
| `bench_medium` | 100 | 50 | 4 | 198 KB |
| `bench_large` | 500 | 100 | 5 | 1.8 MB |

---

## Batch Size Scaling (bench_medium model)

How prediction time scales with batch size.

| Batch Size | booste-rs | Throughput |
|------------|-----------|------------|
| 1 | 874 ns | 1.14 M elem/s |
| 10 | 8.5 µs | 1.18 M elem/s |
| 100 | 86 µs | 1.14 M elem/s |
| 1,000 | 2.19 ms | 457 K elem/s |
| 10,000 | 22.1 ms | 452 K elem/s |

**Observations**:
- Linear scaling with batch size (expected)
- Per-row overhead is minimal
- Throughput slightly decreases at larger batches (cache effects?)

---

## Model Size Scaling (1000 rows)

How prediction time scales with model complexity.

| Model | Trees | booste-rs | Throughput |
|-------|-------|-----------|------------|
| small | 10 | 50.8 µs | 19.7 M elem/s |
| medium | 100 | 2.17 ms | 461 K elem/s |
| large | 500 | 14.7 ms | 68.0 K elem/s |

**Observations**:
- Roughly linear with tree count
- Large model (500 trees, 100 features) is still reasonable at 14.7ms for 1000 rows

---

## XGBoost C++ Comparison

Direct comparison with XGBoost C++ library (via `xgb` Rust bindings).

### Single Row Latency

| Implementation | Time |
|----------------|------|
| booste-rs | 862 ns |
| XGBoost C++ | 4.25 µs |

**booste-rs is ~4.9x faster for single-row prediction!**

### Batch Prediction

| Batch Size | booste-rs | XGBoost C++ | Ratio |
|------------|-----------|-------------|-------|
| 100 | 84 µs | 4.6 µs | XGB 18x faster |
| 1,000 | 2.18 ms | 5.2 µs | XGB 420x faster |
| 10,000 | 21.8 ms | 9.8 µs | XGB 2200x faster |

> ⚠️ **Note**: The XGBoost batch numbers appear suspiciously fast (~1 billion rows/sec).
> This may indicate result caching, lazy evaluation, or a benchmark methodology issue.
> These numbers need investigation before drawing conclusions about batch performance.
> The booste-rs numbers are valid baselines for our own optimization work.

### Analysis

**Single-row**: booste-rs wins significantly. This is likely because:

- No FFI overhead
- No DMatrix construction overhead
- Simple row-at-a-time traversal is efficient

**Batch prediction**: XGBoost C++ numbers need verification. The reported throughput
(~1 billion rows/sec for 10K batch) exceeds what's physically reasonable for a
100-tree model, suggesting the benchmark may not be measuring actual compute.

### Implications for booste-rs

1. **Current strength**: Single-row prediction (real-time serving scenarios)
2. **Opportunity**: Block traversal (M3.4) could significantly improve batch performance
3. **Goal**: Close the gap for batch prediction while maintaining single-row advantage

---

## Key Takeaways

1. **booste-rs is already competitive** for single-row latency use cases (4.9x faster than XGBoost C++)
2. **Batch prediction needs optimization** - this is the focus of M3.4 (Block Traversal)
3. **XGBoost batch comparison needs investigation** - numbers seem unrealistic
4. **Memory layout matters** - our SoA layout should be SIMD-friendly once we implement block traversal

## TODO

- [ ] Investigate XGBoost batch benchmark methodology
- [ ] Add compiler optimization flags (LTO, codegen-units=1) comparison
- [ ] Re-run after M3.4 Block Traversal implementation

---

## Running Benchmarks

```bash
# Basic (booste-rs only)
cargo bench

# With XGBoost comparison
cargo bench --features bench-xgboost

# Generate HTML reports
open target/criterion/report/index.html
```
