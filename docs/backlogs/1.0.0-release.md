# boosters 1.0.0 Release Backlog

**Created**: 2025-12-19  
**Status**: Draft  
**Source**: [Code Audit 2025-12-19](../audits/2025-12-19-code-audit.md)

---

## Round 1: Initial Structure

**Product Owner**: Let's organize the audit findings into epics. I see three natural groupings: API cleanup, documentation, and GPU preparation. What do you all think?

**Architect**: Agreed. But I'd separate "API Cleanup" from "Developer Experience" — the re-export chains are internal plumbing, while `from_file()` is user-facing ergonomics.

**Senior Engineer**: I'd also add a "Technical Debt" epic for the dead code and dependency cleanup. Small items but they accumulate.

**QA Engineer**: For testing, most findings were positive. I'd bundle any test improvements into the relevant epic rather than a separate testing epic.

---

## Round 2: Epic Definition

**Product Owner**: Okay, here's the refined structure:

| Epic | Focus | Priority |
|------|-------|----------|
| E1: Technical Debt | Dependencies, dead code | P0 |
| E2: API Polish | Re-exports, convenience methods | P1 |
| E3: Documentation | README, examples, Quick Start | P1 |
| E4: GPU Foundation | Document extension points | P2 |

**Architect**: E1 should be completed first — it's small and removes noise. E2 and E3 can be parallelized. E4 is documentation only, no code changes.

**Senior Engineer**: For E2, the re-export cleanup is tricky. It's a breaking change for anyone importing from the wrong path.

**QA Engineer**: Good point. But the audit says "no users yet" — we can break freely before 1.0.

---

## Round 3: Story Breakdown

**Product Owner**: Let me draft the stories. Senior, what's realistic for each?

**Senior Engineer**: 

- Dead code removal: 10 min (already identified)
- Re-export cleanup: 1-2 hours (need to trace all paths)
- `XgbModel::from_file()`: 30 min
- `from_row_matrix()`: 30 min
- README examples: 1 hour

**QA Engineer**: For each story, what's the verification? I want clear "done" criteria.

**Architect**: And I want to ensure E2 stories don't break the API stability we're aiming for in 1.0.

---

## Round 4: Definition of Done

**QA Engineer**: Here's my proposal for DoD criteria:

1. **Code changes**: `cargo test` passes, `cargo clippy` clean
2. **Documentation**: `cargo doc` builds without warnings  
3. **API changes**: Public API is documented with examples
4. **Breaking changes**: Noted in CHANGELOG

**Architect**: Add: "Re-exports removed are not in any example or public documentation."

**Product Owner**: Good. Let's also add: "Self-review completed before PR."

---

## Round 5: Story Refinement

**Senior Engineer**: Some stories need clarification:

- **S2.1 (re-exports)**: Should we keep Forest/Tree in `inference` at all? Or pure `repr`?
- **S2.2 (from_row_matrix)**: Should it auto-convert, or return an error for performance?

**Architect**: For S2.1: `repr` owns data structures, `inference` owns prediction. So `Forest` lives in `repr`, but `Predictor` stays in `inference`. No re-exports.

**QA Engineer**: For S2.2: Auto-convert with no warning is safest. Users who care about performance will use `ColMatrix` directly.

**Product Owner**: Settled. Let's finalize the document.

---

## Round 6: Final Review

**Product Owner**: Final pass. Any blockers or concerns?

**Architect**: The GPU foundation epic is light — that's intentional. We're documenting intent, not building infrastructure.

**QA Engineer**: Testing criteria are clear. No concerns.

**Senior Engineer**: Ready to start. E1 can be done today.

**Product Owner**: Approved. Marking as ready for implementation.

---

# Epics & Stories

## Epic 1: Technical Debt Cleanup

**Goal**: Remove dead code and unused dependencies to clean the crate before 1.0.

**Why**: Clean codebase reduces maintenance burden and confusion.

### Story 1.1: Remove Dead Code

**Description**: Remove `BinnedDataset::new()` which is never called.

**Tasks**:
- [x] 1.1.1 Remove `new()` method from `dataset.rs`
- [x] 1.1.2 Update any tests that reference it

**Definition of Done**:
- `cargo build` has no dead_code warnings
- All tests pass

**Status**: ✅ COMPLETE (done during audit)

---

### Story 1.2: Remove Unused Dependencies

**Description**: Remove `derive_builder` which was added but never used.

**Tasks**:
- [x] 1.2.1 Remove from Cargo.toml
- [x] 1.2.2 Verify no compile errors

**Definition of Done**:
- `cargo tree | grep derive_builder` returns nothing
- Build time reduced (verify with `cargo clean && cargo build`)

**Status**: ✅ COMPLETE (done during audit)

---

## Epic 2: API Polish

**Goal**: Establish clean, consistent public API before 1.0 stability guarantees.

**Why**: Confusing re-exports and missing convenience methods hurt adoption.

### Story 2.1: Establish Canonical Import Paths

**Description**: Remove duplicate re-exports so each type has one canonical path.

**Finding**: A-1.1

**Proposed Canonical Paths**:
| Type | Path | Rationale |
|------|------|-----------|
| `Forest` | `boosters::repr::gbdt::Forest` | Data structure |
| `Tree` | `boosters::repr::gbdt::Tree` | Data structure |
| `Node` | `boosters::repr::gbdt::Node` | Data structure |
| `Predictor` | `boosters::inference::gbdt::Predictor` | Prediction logic |
| `TreeTraversal` | `boosters::inference::gbdt::TreeTraversal` | Prediction trait |

**Tasks**:
- [ ] 2.1.1 Remove Forest/Tree/Node re-exports from `inference/mod.rs`
- [ ] 2.1.2 Remove re-exports from `inference/gbdt/mod.rs`
- [ ] 2.1.3 Update internal uses to canonical paths
- [ ] 2.1.4 Update examples and documentation
- [ ] 2.1.5 Add module-level docs explaining where to find types

**Definition of Done**:
- Each public type accessible from exactly one path
- `cargo doc` shows types at canonical locations only
- All examples compile
- Internal code uses canonical imports

**Effort**: 1-2 hours

---

### Story 2.2: Add XgbModel::from_file()

**Description**: Add convenience method for loading XGBoost models, matching LightGBM API.

**Finding**: U-3.3

**Current**:
```rust
let model: XgbModel = serde_json::from_reader(File::open(path)?)?;
```

**Proposed**:
```rust
let model = XgbModel::from_file("model.json")?;
```

**Tasks**:
- [ ] 2.2.1 Add `from_file()` method to `XgbModel`
- [ ] 2.2.2 Add doctest example
- [ ] 2.2.3 Update Quick Start in lib.rs

**Definition of Done**:
- `XgbModel::from_file()` works for valid JSON
- Returns clear error for invalid paths
- Doctest passes

**Effort**: 30 min

---

### Story 2.3: Add from_row_matrix() Convenience

**Description**: Allow training from row-major data without explicit conversion.

**Finding**: U-3.1

**Current**:
```rust
let row_matrix: RowMatrix<f32> = DenseMatrix::from_vec(...);
let col_matrix: ColMatrix<f32> = row_matrix.to_layout();
let dataset = BinnedDatasetBuilder::from_matrix(&col_matrix, 256).build()?;
```

**Proposed**:
```rust
let row_matrix: RowMatrix<f32> = DenseMatrix::from_vec(...);
let dataset = BinnedDatasetBuilder::from_row_matrix(&row_matrix, 256).build()?;
```

**Tasks**:
- [ ] 2.3.1 Add `from_row_matrix()` to `BinnedDatasetBuilder`
- [ ] 2.3.2 Internally convert to column-major
- [ ] 2.3.3 Add doctest
- [ ] 2.3.4 Update examples

**Definition of Done**:
- `from_row_matrix()` produces identical results to manual conversion
- No performance regression (conversion happens once)
- Doctest passes

**Effort**: 30 min

---

## Epic 3: Documentation

**Goal**: Ensure documentation is accurate, helpful, and matches the actual API.

**Why**: First impressions matter. Outdated docs erode trust.

### Story 3.1: Update Quick Start Examples

**Description**: Ensure lib.rs Quick Start works with current API.

**Finding**: U-3.4

**Tasks**:
- [x] 3.1.1 Update training example in lib.rs
- [x] 3.1.2 Update XGBoost loading example
- [ ] 3.1.3 Convert from `ignore` to `no_run` where possible

**Definition of Done**:
- Examples compile (verified by `cargo test --doc`)
- Examples reflect current API

**Status**: Partially complete (examples updated, doctest status pending)

---

### Story 3.2: Add README Code Examples

**Description**: Add runnable code examples to README for training and inference.

**Finding**: U-3.6

**Tasks**:
- [ ] 3.2.1 Add training example (regression)
- [ ] 3.2.2 Add XGBoost model loading example
- [ ] 3.2.3 Add prediction example
- [ ] 3.2.4 Ensure examples match lib.rs Quick Start

**Definition of Done**:
- README has at least 2 code blocks
- Code blocks are syntactically valid Rust
- Examples match actual API

**Effort**: 1 hour

---

### Story 3.3: Document train() Parameters

**Description**: Clarify what the empty arrays in `train(&dataset, &labels, &[], &[])` mean.

**Finding**: U-3.2

**Options**:
1. Better rustdoc on `train()` method
2. Builder pattern for train options
3. Named struct for train options

**Tasks**:
- [ ] 3.3.1 Add documentation explaining sample_weights and validation params
- [ ] 3.3.2 Consider adding `TrainOptions` struct (defer to future story if complex)

**Definition of Done**:
- `train()` rustdoc explains all parameters
- Example shows non-empty validation usage

**Effort**: 30 min

---

### Story 3.4: Review and Fix Ignored Doctests

**Description**: Audit ignored doctests and convert to `no_run` where possible.

**Finding**: Q-2.3

**Tasks**:
- [ ] 3.4.1 List all `ignore` doctests
- [ ] 3.4.2 For each: determine if `no_run` is viable (type-checked but not executed)
- [ ] 3.4.3 Convert viable ones to `no_run`
- [ ] 3.4.4 Document why remaining ones must be `ignore`

**Definition of Done**:
- Reduced count of `ignore` doctests
- All `ignore` doctests have comments explaining why
- `cargo test --doc` passes

**Effort**: 1 hour

---

## Epic 4: GPU Foundation (Documentation Only)

**Goal**: Document GPU extension points so 1.0 API doesn't block future GPU work.

**Why**: Audit confirmed architecture is GPU-ready. Document this for future contributors.

### Story 4.1: Document TreeTraversal Extension Point

**Description**: Add documentation explaining how to implement custom traversal strategies.

**Finding**: E-4.2

**Tasks**:
- [ ] 4.1.1 Add module-level docs to `inference/gbdt/traversal.rs`
- [ ] 4.1.2 Document `TreeTraversal` trait with extension guidance
- [ ] 4.1.3 Note that GPU implementation would use this trait

**Definition of Done**:
- `TreeTraversal` trait has comprehensive rustdoc
- Example skeleton for custom implementation
- GPU extension mentioned in docs

**Effort**: 30 min

---

### Story 4.2: Create GPU Acceleration RFC

**Description**: Create RFC-0020 documenting the GPU acceleration roadmap.

**Finding**: A-1.10, E-4.4

**Content**:
1. Phase 1: GPU Prediction via `TreeTraversal` trait
2. Phase 2: GPU Histograms via new `HistogramBackend` trait
3. Phase 3: Full GPU Training (future scope)

**Tasks**:
- [ ] 4.2.1 Create RFC-0020 GPU Acceleration
- [ ] 4.2.2 Document Phase 1 approach (trait implementation)
- [ ] 4.2.3 Document Phase 2 approach (histogram abstraction)
- [ ] 4.2.4 Mark Phase 3 as future/TBD

**Definition of Done**:
- RFC exists with clear phase definitions
- Links to relevant code locations
- No code changes required

**Effort**: 2 hours

---

## Summary

### Sprint Planning

**Recommended Sprint Order**:

| Sprint | Epics/Stories | Effort |
|--------|---------------|--------|
| 1 (current) | E1 ✅, S2.1, S3.1 | 2-3 hours |
| 2 | S2.2, S2.3, S3.2, S3.3 | 2-3 hours |
| 3 | S3.4, E4 | 3-4 hours |

### Velocity Notes

- E1 already complete from audit
- Most stories are 30min - 1 hour
- Total estimated effort: ~10 hours
- Can be completed in 1-2 focused sessions

### Blocking Issues

None identified. All work is independent.

### Post-1.0 Backlog

Items deferred to after 1.0:

1. **GPU Prediction Implementation** (Phase 1 of RFC-0020)
2. **Python Bindings** (separate epic)
3. **SHAP/Explainability** (separate epic)
4. **Additional Model Formats** (CatBoost, etc.)

---

**Document Status**: Approved for implementation  
**Last Updated**: 2025-12-19
