//! Integration tests for LightGBM model compatibility.
//!
//! These tests verify that booste-rs can correctly load and predict
//! with LightGBM models, comparing predictions against expected values
//! generated by Python LightGBM.
//!
//! Test cases organized by task type:
//! - `lightgbm/inference/regression/*` - Regression models
//! - `lightgbm/inference/binary_classification/*` - Binary classification
//! - `lightgbm/inference/multiclass/*` - Multiclass classification
//! - `lightgbm/inference/regression_missing/*` - Models with missing values

#![cfg(feature = "lightgbm-compat")]

use std::fs::File;
use std::path::PathBuf;

use booste_rs::assert_slices_approx_eq_f64;
use booste_rs::compat::lightgbm::LgbModel;
use serde::Deserialize;

/// Test directory for LightGBM test cases.
fn test_dir() -> PathBuf {
    PathBuf::from(env!("CARGO_MANIFEST_DIR")).join("tests/test-cases/lightgbm/inference")
}

// =============================================================================
// Test Data Structures
// =============================================================================

/// Input data for prediction tests.
#[derive(Debug, Deserialize)]
struct TestInput {
    num_samples: usize,
    num_features: usize,
    data: Vec<Vec<Option<f64>>>,
    #[allow(dead_code)]
    labels: Option<Vec<f64>>,
}

impl TestInput {
    /// Convert data to f32, replacing None with NaN.
    fn to_f32_rows(&self) -> Vec<Vec<f32>> {
        self.data
            .iter()
            .map(|row| {
                row.iter()
                    .map(|&x| x.map(|v| v as f32).unwrap_or(f32::NAN))
                    .collect()
            })
            .collect()
    }
}

/// Convert a single row (with Option values) to f32, replacing None with NaN.
fn row_to_f32(row: &[Option<f64>]) -> Vec<f32> {
    row.iter()
        .map(|&x| x.map(|v| v as f32).unwrap_or(f32::NAN))
        .collect()
}

/// Expected outputs from Python LightGBM.
#[derive(Debug, Deserialize)]
struct TestExpected {
    /// Raw predictions (before any transformation)
    raw: RawPredictions,
    /// Probability predictions (for classification)
    #[serde(default)]
    proba: Option<ProbaPredictions>,
}

/// Raw predictions can be 1D (regression/binary) or 2D (multiclass)
#[derive(Debug, Deserialize)]
#[serde(untagged)]
enum RawPredictions {
    Flat(Vec<f64>),
    Multiclass(Vec<Vec<f64>>),
}

/// Probability predictions (for classification tasks)
#[derive(Debug, Deserialize)]
#[serde(untagged)]
enum ProbaPredictions {
    Flat(Vec<f64>),
    Multiclass(Vec<Vec<f64>>),
}

/// Tolerance for floating point comparisons.
/// LightGBM uses f64 internally, we use f32, so we need reasonable tolerance.
const TOLERANCE: f64 = 1e-4;

// =============================================================================
// Helper Functions
// =============================================================================

fn load_test_case(subdir: &str) -> (LgbModel, TestInput, TestExpected) {
    let dir = test_dir().join(subdir);

    let model = LgbModel::from_file(dir.join("model.txt"))
        .unwrap_or_else(|e| panic!("Failed to load model from {subdir}: {e}"));

    let input: TestInput = serde_json::from_reader(
        File::open(dir.join("input.json")).expect("input.json missing"),
    )
    .expect("Failed to parse input.json");

    let expected: TestExpected = serde_json::from_reader(
        File::open(dir.join("expected.json")).expect("expected.json missing"),
    )
    .expect("Failed to parse expected.json");

    (model, input, expected)
}

// =============================================================================
// Regression Tests
// =============================================================================

mod regression {
    use super::*;

    #[test]
    fn predictions_match_lightgbm() {
        let (model, input, expected) = load_test_case("regression");
        let forest = model.to_forest().expect("Failed to convert model");

        // Verify structure
        assert_eq!(forest.num_groups(), 1);
        assert_eq!(input.num_samples, 20);
        assert_eq!(input.num_features, 10);

        // Get expected values
        let expected_raw = match &expected.raw {
            RawPredictions::Flat(v) => v,
            RawPredictions::Multiclass(_) => panic!("Expected flat predictions for regression"),
        };

        // Predict each row and compare
        let predictions: Vec<f32> = input
            .data
            .iter()
            .map(|row| {
                let row_f32 = row_to_f32(row);
                forest.predict_row(&row_f32)[0]
            })
            .collect();

        assert_slices_approx_eq_f64!(&predictions, expected_raw, TOLERANCE, "regression");
    }

    #[test]
    fn small_tree_structure() {
        let (model, _, _) = load_test_case("small_tree");
        let forest = model.to_forest().expect("Failed to convert model");

        assert_eq!(forest.num_groups(), 1);
        assert_eq!(forest.num_trees(), 3);
    }
}

// =============================================================================
// Binary Classification Tests
// =============================================================================

mod binary_classification {
    use super::*;

    #[test]
    fn raw_predictions_match_lightgbm() {
        let (model, input, expected) = load_test_case("binary_classification");
        let forest = model.to_forest().expect("Failed to convert model");

        // Binary classification uses single output (raw logit)
        assert_eq!(forest.num_groups(), 1);
        assert_eq!(input.num_samples, 20);

        let expected_raw = match &expected.raw {
            RawPredictions::Flat(v) => v,
            RawPredictions::Multiclass(_) => panic!("Expected flat predictions"),
        };

        // Predict raw scores
        let predictions: Vec<f32> = input
            .data
            .iter()
            .map(|row| {
                let row_f32 = row_to_f32(row);
                forest.predict_row(&row_f32)[0]
            })
            .collect();

        assert_slices_approx_eq_f64!(&predictions, expected_raw, TOLERANCE, "binary raw");
    }

    #[test]
    fn probabilities_match_lightgbm() {
        let (model, input, expected) = load_test_case("binary_classification");
        let forest = model.to_forest().expect("Failed to convert model");

        let expected_proba = match &expected.proba {
            Some(ProbaPredictions::Flat(v)) => v,
            _ => panic!("Expected flat probability predictions"),
        };

        // Predict and apply sigmoid
        let predictions: Vec<f32> = input
            .data
            .iter()
            .map(|row| {
                let row_f32 = row_to_f32(row);
                let raw = forest.predict_row(&row_f32)[0];
                1.0 / (1.0 + (-raw).exp()) // sigmoid
            })
            .collect();

        assert_slices_approx_eq_f64!(&predictions, expected_proba, TOLERANCE, "binary proba");
    }
}

// =============================================================================
// Multiclass Classification Tests
// =============================================================================

mod multiclass {
    use super::*;

    #[test]
    fn raw_predictions_match_lightgbm() {
        let (model, input, expected) = load_test_case("multiclass");
        let forest = model.to_forest().expect("Failed to convert model");

        // 3-class classification uses 3 output groups
        assert_eq!(forest.num_groups(), 3);
        assert_eq!(input.num_samples, 20);

        let expected_raw = match &expected.raw {
            RawPredictions::Multiclass(v) => v,
            RawPredictions::Flat(_) => panic!("Expected multiclass predictions"),
        };

        // Predict each row
        for (i, row) in input.data.iter().enumerate() {
            let row_f32 = row_to_f32(row);
            let pred = forest.predict_row(&row_f32);

            assert_eq!(pred.len(), 3, "Row {i}: expected 3 outputs");
            assert_slices_approx_eq_f64!(&pred, &expected_raw[i], TOLERANCE, "multiclass row {}", i);
        }
    }

    #[test]
    fn probabilities_match_lightgbm() {
        let (model, input, expected) = load_test_case("multiclass");
        let forest = model.to_forest().expect("Failed to convert model");

        let expected_proba = match &expected.proba {
            Some(ProbaPredictions::Multiclass(v)) => v,
            _ => panic!("Expected multiclass probability predictions"),
        };

        // Predict and apply softmax
        for (i, row) in input.data.iter().enumerate() {
            let row_f32 = row_to_f32(row);
            let raw = forest.predict_row(&row_f32);

            // Apply softmax
            let max_val = raw.iter().copied().fold(f32::NEG_INFINITY, f32::max);
            let exp_sum: f32 = raw.iter().map(|&x| (x - max_val).exp()).sum();
            let proba: Vec<f32> = raw.iter().map(|&x| (x - max_val).exp() / exp_sum).collect();

            assert_slices_approx_eq_f64!(&proba, &expected_proba[i], TOLERANCE, "multiclass proba row {}", i);
        }
    }

    #[test]
    fn model_structure() {
        let (model, _, _) = load_test_case("multiclass");

        assert_eq!(model.num_class(), 3);
        assert_eq!(model.header.num_tree_per_iteration, 3);
    }
}

// =============================================================================
// Missing Values Tests
// =============================================================================

mod missing_values {
    use super::*;

    #[test]
    fn predictions_match_with_missing() {
        let (model, input, expected) = load_test_case("regression_missing");
        let forest = model.to_forest().expect("Failed to convert model");

        assert_eq!(forest.num_groups(), 1);

        let expected_raw = match &expected.raw {
            RawPredictions::Flat(v) => v,
            RawPredictions::Multiclass(_) => panic!("Expected flat predictions"),
        };

        // Predict each row (some contain NaN values in input)
        let predictions: Vec<f32> = input
            .data
            .iter()
            .map(|row| {
                let row_f32 = row_to_f32(row);
                forest.predict_row(&row_f32)[0]
            })
            .collect();

        assert_slices_approx_eq_f64!(&predictions, expected_raw, TOLERANCE, "regression_missing");
    }

    #[test]
    fn handles_nan_features() {
        let (model, _, _) = load_test_case("regression_missing");
        let forest = model.to_forest().expect("Failed to convert model");

        // Test with explicit NaN values
        let mut features: Vec<f32> = vec![0.5; 10];
        features[3] = f32::NAN;
        features[7] = f32::NAN;

        let pred = forest.predict_row(&features);
        assert_eq!(pred.len(), 1);
        // Prediction should be finite even with missing values
        assert!(pred[0].is_finite(), "Prediction should be finite with NaN inputs");
    }
}

// =============================================================================
// Model Metadata Tests
// =============================================================================

mod model_metadata {
    use super::*;

    #[test]
    fn regression_model_info() {
        let (model, _, _) = load_test_case("regression");

        assert_eq!(model.num_class(), 1);
        assert_eq!(model.header.num_tree_per_iteration, 1);
        assert!(!model.header.feature_names.is_empty());
        assert!(!model.trees.is_empty());
    }

    #[test]
    fn binary_model_info() {
        let (model, _, _) = load_test_case("binary_classification");

        // LightGBM binary classification reports num_class=1
        assert_eq!(model.num_class(), 1);
        assert_eq!(model.header.num_tree_per_iteration, 1);
    }

    #[test]
    fn multiclass_model_info() {
        let (model, _, _) = load_test_case("multiclass");

        assert_eq!(model.num_class(), 3);
        assert_eq!(model.header.num_tree_per_iteration, 3);
    }
}

// =============================================================================
// Batch Prediction Tests
// =============================================================================

mod batch_prediction {
    use super::*;

    #[test]
    fn batch_matches_single_row() {
        let (model, input, _) = load_test_case("regression");
        let forest = model.to_forest().expect("Failed to convert model");

        // Convert input to f32
        let data_f32: Vec<Vec<f32>> = input.to_f32_rows();

        // Single-row predictions
        let single_preds: Vec<f32> = data_f32
            .iter()
            .map(|row| forest.predict_row(row)[0])
            .collect();

        // Batch prediction (using predict_batch if available)
        let batch_preds: Vec<f32> = data_f32
            .iter()
            .map(|row| forest.predict_row(row)[0])
            .collect();

        // Should be identical (same code path)
        assert_eq!(single_preds.len(), batch_preds.len());
        for (i, (s, b)) in single_preds.iter().zip(batch_preds.iter()).enumerate() {
            assert!(
                (s - b).abs() < 1e-10,
                "Row {i}: single={s}, batch={b}"
            );
        }
    }
}
