# booste-rs

A fast, pure-Rust gradient boosting inference library. Load XGBoost models and predict without any C++ dependencies.

## Features

- ðŸš€ **Pure Rust** - No C++ dependencies for core inference
- ðŸ“¦ **XGBoost Compatible** - Load models from XGBoost JSON format
- ðŸŽ¯ **Feature Complete** - Supports regression, binary classification, multiclass
- ðŸŒ³ **DART Support** - Full DART booster with tree weights
- ðŸ“Š **Categorical Features** - Native categorical split support
- ðŸ”¢ **Missing Values** - Proper NaN handling

## Quick Start

```rust
use booste_rs::model::Model;
use booste_rs::data::DenseMatrix;

// Load a model from XGBoost JSON
let model = Model::from_xgboost_json("model.json")?;

// Create input features
let features = DenseMatrix::from_vec(data, num_rows, num_features);

// Predict
let predictions = model.predict(&features);
```

## Installation

Add to your `Cargo.toml`:

```toml
[dependencies]
booste-rs = { version = "0.1", features = ["xgboost-compat"] }
```

## Benchmarks

We use [Criterion](https://github.com/bheisler/criterion.rs) for benchmarking.

### Running Benchmarks

**Basic benchmarks (booste-rs only):**

```bash
cargo bench
```

**With XGBoost C++ comparison:**

```bash
cargo bench --features bench-xgboost
```

### XGBoost Comparison Prerequisites

The `bench-xgboost` feature uses the [`xgb`](https://crates.io/crates/xgb) crate which provides Rust bindings to the XGBoost C++ library. This requires some system dependencies:

#### Arch Linux

```bash
sudo pacman -S clang
```

#### Ubuntu / Debian

```bash
sudo apt install libclang-dev
```

#### macOS

```bash
# Install Xcode command line tools (includes clang)
xcode-select --install

# Install OpenMP for XGBoost
brew install libomp
```

#### Windows

The `xgb` crate provides prebuilt binaries for Windows x64.

### Generating Benchmark Models

Benchmark models are generated by the Python test data script:

```bash
cd tools/data_generation
uv run python scripts/generate_test_cases.py
```

This creates models of various sizes in `tests/test-cases/benchmark/`:

| Model | Trees | Features | Depth | File Size |
|-------|-------|----------|-------|-----------|
| `bench_small` | 10 | 5 | 3 | ~12 KB |
| `bench_medium` | 100 | 50 | 4 | ~200 KB |
| `bench_large` | 500 | 100 | 5 | ~1.8 MB |

### Understanding Results

Benchmark reports are generated in `target/criterion/`. Key metrics:

- **Single-row latency**: Time to predict one sample (important for real-time serving)
- **Batch throughput**: Samples per second for bulk prediction
- **Model complexity scaling**: How performance changes with tree count

## Development

### Running Tests

```bash
# Run all tests
cargo test --features xgboost-compat

# Generate test data (requires Python + XGBoost)
cd tools/data_generation
uv run python scripts/generate_test_cases.py
```

### Project Structure

```
src/
â”œâ”€â”€ lib.rs              # Library root
â”œâ”€â”€ model.rs            # High-level Model API
â”œâ”€â”€ objective.rs        # Output transformations (sigmoid, softmax)
â”œâ”€â”€ compat/             # Format compatibility
â”‚   â””â”€â”€ xgboost/        # XGBoost JSON loader
â”œâ”€â”€ data/               # Data matrix abstractions
â”œâ”€â”€ forest/             # Forest (ensemble) structures
â”œâ”€â”€ predict/            # Prediction visitor pattern
â””â”€â”€ trees/              # Tree storage and traversal

design/                 # Architecture documents and RFCs
tests/                  # Integration tests
benches/                # Criterion benchmarks
```

## License

MIT OR Apache-2.0
